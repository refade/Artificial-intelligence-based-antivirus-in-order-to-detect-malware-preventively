function [TrainingTime, TestingTime, TrainingAccuracy, TestingAccuracy] = MLP(Data_File, NumberofHiddenLayers, NumberofHiddenNeurons, ActivationFunction, seed)
	
%    de Lima, S.M.L., Silva, H.K.d.L., Luz, J.H.d.S. et al. 
%    Artificial intelligence-based antivirus in order to detect malware preventively. 
%    Prog Artif Intell 10, 1â€“22 (2021). https://doi.org/10.1007/s13748-020-00220-4
	
% Usage: MLP(Data_File, NumberofHiddenLayers, NumberofHiddenNeurons, ActivationFunction, seed)
% OR:    [TrainingTime, TestingTime, TrainingAccuracy, TestingAccuracy] = MLP(Data_File, NumberofHiddenLayers, NumberofHiddenNeurons, ActivationFunction, seed)
%
% Input:
% Data_File     - Filename of data set
% NumberofHiddenLayers	- Number of hidden layers
% NumberofHiddenNeurons - Number of hidden neurons assigned to the MLP
% ActivationFunction    - Type of activation function:
%								'trainb'	for Batch training with weight & bias learning rules
%								'traincgb'  for Powell-Beale conjugate gradient backpropagation
%								'traincgf'  for Fletcher-Powell conjugate gradient backpropagation
%								'traincgp'  for Polak-Ribiere conjugate gradient backpropagation
%								'traingd'   for Gradient descent backpropagation
%								'traingdm'	for Gradient descent with momentum backpropagation
%								'traingda'	for Gradient descent with adaptive lr backpropagation
%								'traingdx'	for Gradient descent w/momentum & adaptive lr backpropagation
%								'trainoss'	for One step secant backpropagation
%								'trainrp'	for Resilient backpropagation (Rprop)
%								'trainscg'	for Scaled conjugate gradient backpropagation	
% seed					- Control random number generation, default: 0

%
% Output: 
% TrainingTime          - Time (seconds) spent on training MLP
% TestingTime           - Time (seconds) spent on predicting ALL testing data
% TrainingAccuracy      - Training accuracy: 
%                           RMSE for regression or correct classification rate for classification
% TestingAccuracy       - Testing accuracy: 
%                           RMSE for regression or correct classification rate for classification
%
% Donwload and unzip http://www.extreme-learning-machines.org/source_codes/diabetes_train.zip
% load('diabetes_train');
% Sample classification: [TrainingTime, TestingTime, TrainingAccuracy, TestingAccuracy] = MLP('diabetes_train', 1, 500, 'traincgb', 0)
%
	
%%%%%%%%%%% Load dataset
clc;
data=load(Data_File);
output=data(:,1)';
input=data(:,2:size(data,2))';

[output] = fillInDataMLP(output);

clear data;                                   %   Release raw data array

if NumberofHiddenLayers==1
    net = patternnet(NumberofHiddenNeurons, ActivationFunction);
elseif NumberofHiddenLayers==2
    net = patternnet([NumberofHiddenNeurons NumberofHiddenNeurons], ActivationFunction);
elseif NumberofHiddenLayers==3
    net = patternnet([NumberofHiddenNeurons NumberofHiddenNeurons NumberofHiddenNeurons], ActivationFunction);
elseif NumberofHiddenLayers==4
    net = patternnet([NumberofHiddenNeurons NumberofHiddenNeurons NumberofHiddenNeurons NumberofHiddenNeurons], ActivationFunction);
else
    net = patternnet([NumberofHiddenNeurons NumberofHiddenNeurons NumberofHiddenNeurons NumberofHiddenNeurons NumberofHiddenNeurons], ActivationFunction);
end

net.divideFcn = 'divideblock';
net.divideParam.trainRatio = 70/100; %70% for train
net.divideParam.valRatio = 15/100;   %15% for cross validation
net.divideParam.testRatio = 15/100;  %15% for test 

s = RandStream('mt19937ar','Seed',seed);
RandStream.setGlobalStream(s);
%==========================================================================
%			Train
%==========================================================================
start_time_train=cputime;
[net,tr] = train(net,input,output);
end_time_train=cputime;
TrainingTime=end_time_train-start_time_train;        %   Calculate CPU time (seconds) spent for training ELM
clear P; %   Release input of training data 

trInd = tr.trainInd;
trainOutputs = net(input(:,trInd));
[CorretClassification, MissClassification,TrainingAccuracy] = evaluationNetwork(numel(trInd), trainOutputs, output(:,trInd));
%==========================================================================
%			Test
%==========================================================================
start_time_test=cputime;
tInd = tr.testInd;
tstOutputs = net(input(:,tInd));
end_time_test=cputime;
TestingTime = end_time_test-start_time_test;

[CorretClassification, MissClassification,TestingAccuracy] = evaluationNetwork(numel(tInd), tstOutputs, output(:,tInd)); 
%==========================================================================
 function [CorretClassification, MissClassification,accuracy] = evaluationNetwork(numTeste, outputNetwork, outputDesired)

    
    NumberofOutputNeurons = numel(unique(outputDesired));
    
    [maxOutputNetwork, winnerNetwork] = max (outputNetwork);
    [maxOutputDesired, winnerDesired] = max (outputDesired);

    MissClassification = [];
    CorretClassification = [];
    
    for j=1:NumberofOutputNeurons
        MissClassification(j) = 0;
        CorretClassification(j) = 0;
    end
    
	wrongClass = 0;
	    
    for pat = 1 : numTeste
        %------------------------------------------------------------------
        if winnerNetwork(pat) ~= winnerDesired(pat),
			wrongClass = wrongClass + 1;
        end		
        %------------------------------------------------------------------
        for j=1:NumberofOutputNeurons
            if winnerDesired(pat)==j
                if winnerNetwork(pat) ==j
					CorretClassification(j) = CorretClassification(j) +1;
				else
					MissClassification(j) = MissClassification(j) +1;
				end
            end
        end
        %------------------------------------------------------------------
    end
    
    accuracy=1-(wrongClass/numTeste);
%==========================================================================
function [outputMLP] = fillInDataMLP(output)

    NumberofOutputNeurons = numel(unique(output));
    increment = any(output(:) == 0);
    
    outputMLP = zeros(NumberofOutputNeurons,size(output,2),'double');
     
    for j=1:size(output,2)
        outputMLP(output(1,j)+increment,j) = 1;
    end
    
